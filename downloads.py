#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script para baixar os recursos necessÃ¡rios do NLTK
Execute este script antes de rodar sua anÃ¡lise de sentimentos
"""

import nltk
import ssl

def baixar_recursos_nltk():
    """Baixa todos os recursos necessÃ¡rios do NLTK"""
    
    # Contorna problemas de SSL em alguns sistemas
    try:
        _create_unverified_https_context = ssl._create_unverified_context
    except AttributeError:
        pass
    else:
        ssl._create_default_https_context = _create_unverified_https_context
    
    print("Baixando recursos do NLTK...")
    print("=" * 50)
    
    # Lista de recursos essenciais para anÃ¡lise de sentimentos
    recursos = [
        'punkt',           # Tokenizador de sentenÃ§as
        'punkt_tab',       # Nova versÃ£o do punkt
        'stopwords',       # Palavras irrelevantes
        'vader_lexicon',   # LÃ©xico para anÃ¡lise de sentimentos
        'wordnet',         # Base de dados lexical
        'omw-1.4',         # Multilingual wordnet
        'rslp',            # Stemmer para portuguÃªs
        'floresta',        # Corpus em portuguÃªs
        'mac_morpho',      # Corpus morfolÃ³gico do portuguÃªs
        'averaged_perceptron_tagger',  # POS tagger
    ]
    
    # Baixa cada recurso
    for recurso in recursos:
        try:
            print(f"Baixando {recurso}...")
            nltk.download(recurso, quiet=False)
            print(f"âœ“ {recurso} baixado com sucesso!")
        except Exception as e:
            print(f"âœ— Erro ao baixar {recurso}: {e}")
    
    print("\n" + "=" * 50)
    print("Download concluÃ­do!")
    
    # Testa se os recursos foram instalados corretamente
    print("\nTestando recursos...")
    try:
        from nltk.tokenize import word_tokenize, sent_tokenize
        from nltk.corpus import stopwords
        from nltk.sentiment import SentimentIntensityAnalyzer
        
        # Teste bÃ¡sico
        texto_teste = "Este Ã© um teste. Vamos verificar se tudo funciona!"
        tokens = word_tokenize(texto_teste)
        sentencas = sent_tokenize(texto_teste)
        
        print("âœ“ TokenizaÃ§Ã£o funcionando!")
        print(f"  Tokens: {tokens}")
        print(f"  SentenÃ§as: {sentencas}")
        
        # Teste stopwords
        stop_words = stopwords.words('portuguese')
        print(f"âœ“ Stopwords carregadas! ({len(stop_words)} palavras)")
        
        # Teste VADER
        analyzer = SentimentIntensityAnalyzer()
        scores = analyzer.polarity_scores("I love this!")
        print(f"âœ“ VADER funcionando! Scores: {scores}")
        
    except Exception as e:
        print(f"âœ— Erro no teste: {e}")
        return False
    
    print("\nðŸŽ‰ Todos os recursos do NLTK foram instalados e testados com sucesso!")
    return True

if __name__ == "__main__":
    baixar_recursos_nltk()